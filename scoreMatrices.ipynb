{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443c4355",
   "metadata": {},
   "source": [
    "## Score the predicted Hi-C matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hicrep import hicrepSCC\n",
    "from hicexplorer import hicFindTADs\n",
    "import pygenometracks\n",
    "import matplotlib.pyplot as plt\n",
    "import cooler\n",
    "import traceback\n",
    "from sklearn import metrics as metrics\n",
    "from scipy import sparse\n",
    "from hicrep.utils import readMcool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/Users/wolffjoa/data_local/hicgan/hyperparameter'\n",
    "\n",
    "ROOT_PATH_25KB = os.path.join(ROOT_PATH, 'hyperparameter_paper_25kb/')\n",
    "ROOT_PATH_25KB_predicted = os.path.join(ROOT_PATH_25KB, \"predicted\")\n",
    "hic_matrix_25kb_path = os.path.join(ROOT_PATH_25KB, 'GM12878_25kb_cooler_coarsen_chr1.cool')\n",
    "files_25kb = os.listdir(ROOT_PATH_25KB_predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42aa3d5",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrixFromCooler(pCoolerFilePath, pChromNameStr):\n",
    "    #returns sparse csr matrix from cooler file for given chromosome name\n",
    "    sparseMatrix = None\n",
    "    binSizeInt = 0\n",
    "    try:\n",
    "        coolerMatrix = cooler.Cooler(pCoolerFilePath)\n",
    "        sparseMatrix = coolerMatrix.matrix(sparse=True,balance=False).fetch(pChromNameStr)\n",
    "        sparseMatrix = sparseMatrix.tocsr() #so it can be sliced later\n",
    "        binSizeInt = int(coolerMatrix.binsize)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(coolerMatrix.chromnames)\n",
    "        print(e)\n",
    "    return sparseMatrix, binSizeInt\n",
    "\n",
    "def computePearsonCorrelation(pCoolerFile1, pCoolerFile2, \n",
    "                              pWindowsize_bp,\n",
    "                              pModelChromList, pTargetChromStr,\n",
    "                              pModelCellLineList, pTargetCellLineStr,\n",
    "                              pPlotOutputFile=None, pCsvOutputFile=None):\n",
    "    '''\n",
    "    compute distance-stratified pearson correlation for target chromosome\n",
    "    directly from cooler files and plot or write to file\n",
    "\n",
    "    Parameters:\n",
    "        pCoolerFile1 (str): Path to cooler file 1\n",
    "        pCoolerFile2 (str): Path to cooler file 2\n",
    "        pWindowsize_bp (int): Windowsize in basepairs for which correlations shall be computed\n",
    "        pModelChromList (list): List of strings, will appear in plot title\n",
    "        pModelCellLineList (list): List of strings, will appear in plot title\n",
    "        pTargetChromStr (str): the target chromosome, e.g. >chr10< or >10<\n",
    "        pTargetCellLineStr (str): the target cell line, will appear in plot title\n",
    "        pPlotOutputFile (str): filename of correlation plot\n",
    "        pCsvOutputFile (str): filename of correlation csv file\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    ''' \n",
    "\n",
    "    sparseMatrix1, binsize1 = getMatrixFromCooler(pCoolerFile1, pTargetChromStr)\n",
    "    sparseMatrix2, binsize2 = getMatrixFromCooler(pCoolerFile2, pTargetChromStr)\n",
    "    errorMsg = \"\"\n",
    "    if sparseMatrix1 is None:\n",
    "        errorMsg += \"Chrom {:s} could not be loaded from {:s}\\n\"\n",
    "        errorMsg = errorMsg.format(str(pTargetChromStr), pCoolerFile1)\n",
    "    if sparseMatrix2 is None:\n",
    "        errorMsg += \"Chrom {:s} could not be loaded from {:s}\\n\"\n",
    "        errorMsg = errorMsg.format(str(pTargetChromStr), pCoolerFile2)\n",
    "    if errorMsg != \"\":\n",
    "        errorMsg += \"Potential reasons: Wrong file format, wrong chromosome naming scheme or chromosome missing\"\n",
    "        raise SystemExit(errorMsg)\n",
    "    if binsize1 != binsize2:\n",
    "        errorMsg = \"Aborting. Binsizes of matrices are not equal\\n\"\n",
    "        errorMsg += \"{:s} -- {:d}bp\\n\"\n",
    "        errorMsg += \"{:s} -- {:d}bp\\n\"\n",
    "        errorMsg = errorMsg.format(pCoolerFile1,binsize1, pCoolerFile2, binsize2)\n",
    "        raise SystemExit(errorMsg)\n",
    "    resultsDf = computePearsonCorrelationSparse(pSparseCsrMatrix1= sparseMatrix1,\n",
    "                                                pSparseCsrMatrix2= sparseMatrix2,\n",
    "                                                pBinsize= binsize1,\n",
    "                                                pWindowsize_bp= pWindowsize_bp,\n",
    "                                                pModelChromList= pModelChromList,\n",
    "                                                pTargetChromStr= pTargetChromStr,\n",
    "                                                pModelCellLineList= pModelCellLineList,\n",
    "                                                pTargetCellLineStr= pTargetCellLineStr)\n",
    "    if pCsvOutputFile is not None:\n",
    "        resultsDf.to_csv(pCsvOutputFile)\n",
    "    if pPlotOutputFile is not None:\n",
    "        plotPearsonCorrelationDf(pResultsDfList=[resultsDf], \n",
    "                                 pLegendList=[\"Pearson corr.\"],\n",
    "                                 pOutfile=pPlotOutputFile,\n",
    "                                 pMethod=\"pearson\")\n",
    "    return resultsDf\n",
    "\n",
    "def maskFunc(pArray, pWindowSize=0):\n",
    "    #mask a trapezoid along the (main) diagonal of a 2D array\n",
    "    #this code is copied from the study project by Ralf Krauth\n",
    "    #https://github.com/MasterprojectRK/HiCPrediction/blob/master/hicprediction/createTrainingSet.py\n",
    "    maskArray = np.zeros(pArray.shape)\n",
    "    upperTriaInd = np.triu_indices(maskArray.shape[0]) # pylint: disable=unsubscriptable-object\n",
    "    notRequiredTriaInd = np.triu_indices(maskArray.shape[0], k=pWindowSize) # pylint: disable=unsubscriptable-object\n",
    "    maskArray[upperTriaInd] = 1\n",
    "    maskArray[notRequiredTriaInd] = 0\n",
    "    return maskArray\n",
    "\n",
    "def computePearsonCorrelationSparse(pSparseCsrMatrix1, pSparseCsrMatrix2, \n",
    "                                    pBinsize, pWindowsize_bp, \n",
    "                                    pModelChromList, pTargetChromStr, \n",
    "                                    pModelCellLineList, pTargetCellLineStr):\n",
    "    '''\n",
    "    compute distance-stratified Pearson correlation from two sparse matrices\n",
    "\n",
    "    Parameters:\n",
    "        pSparseCsrMatrix1 (scipy.sparse.csr_matrix): sparse csr matrix 1\n",
    "        pSparseCsrMatrix2 (scipy.sparse.csr_matrix): sparse csr matrix 2\n",
    "        pBinsize (int): the binsize of each bin in the sparse matrices\n",
    "        pWindowsize_bp (int): the windowsize in basepairs for which correlations shall be computed\n",
    "        pModelChromList (list): list of strings, will appear in plot title\n",
    "        pTargetChromStr (str): the target chromosome, e.g. >chr10< or >10<\n",
    "        pTargetCellLineStr (str): the target cell line, will appear in plot title\n",
    "        pModelCellLineList (list): List of strings, will appear in plot title\n",
    "\n",
    "    Returns:\n",
    "        (pandas.DataFrame): Pandas dataframe containing the correlations per distance \n",
    "    '''\n",
    "    numberOfDiagonals = int(np.round(pWindowsize_bp/pBinsize))\n",
    "    if numberOfDiagonals < 1:\n",
    "        msg = \"Window size must be larger than bin size of matrices.\\n\"\n",
    "        msg += \"Remember to specify window in basepairs, not bins.\"\n",
    "        raise SystemExit(msg)\n",
    "    shape1 = pSparseCsrMatrix1.shape\n",
    "    shape2 = pSparseCsrMatrix2.shape\n",
    "    if shape1 != shape2:\n",
    "        msg = \"Aborting. Shapes of matrices are not equal.\\n\"\n",
    "        msg += \"Shape 1: ({:d},{:d}); Shape 2: ({:d},{:d})\"\n",
    "        msg = msg.format(shape1[0],shape1[1],shape2[0],shape2[1])\n",
    "        raise SystemExit(msg)\n",
    "    if numberOfDiagonals > shape1[0]-1:\n",
    "        msg = \"Aborting. Window size {0:d} larger than matrix size {:d}\"\n",
    "        msg = msg.format(numberOfDiagonals, shape1[0]-1)\n",
    "        raise SystemExit(msg)\n",
    "    \n",
    "    trapezIndices = np.mask_indices(shape1[0],maskFunc,k=numberOfDiagonals)\n",
    "    reads1 = np.array(pSparseCsrMatrix1[trapezIndices])[0]\n",
    "    reads2 = np.array(pSparseCsrMatrix2[trapezIndices])[0]\n",
    "\n",
    "    matrixDf = pd.DataFrame(columns=['first','second','distance','reads1','reads2'])\n",
    "    matrixDf['first'] = np.uint32(trapezIndices[0])\n",
    "    matrixDf['second'] = np.uint32(trapezIndices[1])\n",
    "    matrixDf['distance'] = np.uint32(matrixDf['second'] - matrixDf['first'])\n",
    "    matrixDf['reads1'] = np.float32(reads1)\n",
    "    matrixDf['reads2'] = np.float32(reads2)\n",
    "    matrixDf.fillna(0, inplace=True)\n",
    "\n",
    "    pearsonAucIndices, pearsonAucValues = getCorrelation(matrixDf,'distance', 'reads1', 'reads2', 'pearson')\n",
    "    pearsonAucScore = metrics.auc(pearsonAucIndices, pearsonAucValues)\n",
    "    spearmanAucIncides, spearmanAucValues = getCorrelation(matrixDf,'distance', 'reads1', 'reads2', 'spearman')\n",
    "    spearmanAucScore = metrics.auc(spearmanAucIncides, spearmanAucValues)\n",
    "    # print(\"PearsonAUC: {:.3f}\".format(pearsonAucScore))\n",
    "    # print(\"SpearmanAUC: {:.3f}\".format(spearmanAucScore))\n",
    "\n",
    "    columns = [\"corrMeth\", \"modelChroms\", \"targetChrom\", \n",
    "                           \"modelCellLines\", \"targetCellLine\", \n",
    "                           \"R2\", \"MSE\", \"MAE\", \"MSLE\", \"AUC\",\n",
    "                           \"binsize\", \"windowsize\"]\n",
    "    columns.extend(sorted(list(matrixDf.distance.unique())))\n",
    "    resultsDf = pd.DataFrame(columns=columns)\n",
    "    resultsDf[\"corrMeth\"] = [\"pearson\", \"spearman\"]\n",
    "    resultsDf.set_index(\"corrMeth\", inplace=True)\n",
    "    resultsDf.loc[:, 'modelChroms'] = \", \".join([str(x) for x in pModelChromList])\n",
    "    resultsDf.loc[:, 'targetChrom'] = pTargetChromStr\n",
    "    resultsDf.loc[:, 'modelCellLines'] = \", \".join([str(x) for x in pModelCellLineList])\n",
    "    resultsDf.loc[:, 'targetCellLine'] = pTargetCellLineStr\n",
    "    resultsDf.loc[:, \"R2\"] = metrics.r2_score(matrixDf['reads2'], matrixDf['reads1'])\n",
    "    resultsDf.loc[:, 'MSE'] = metrics.mean_squared_error( matrixDf['reads2'], matrixDf['reads1'])\n",
    "    resultsDf.loc[:, 'MAE'] = metrics.mean_absolute_error( matrixDf['reads2'], matrixDf['reads1'])\n",
    "    resultsDf.loc[:, 'MSLE'] = metrics.mean_squared_log_error(matrixDf['reads2'], matrixDf['reads1'])\n",
    "    resultsDf.loc['pearson', 'AUC'] = pearsonAucScore \n",
    "    resultsDf.loc['spearman', 'AUC'] = spearmanAucScore\n",
    "    resultsDf.loc[:, 'binsize'] = pBinsize\n",
    "    resultsDf.loc[:, 'windowsize'] = pWindowsize_bp\n",
    "    \n",
    "    for pearsonIndex, corrValue in zip(pearsonAucIndices,pearsonAucValues):\n",
    "        columnName = int(round(pearsonIndex * matrixDf.distance.max()))\n",
    "        resultsDf.loc[\"pearson\", columnName] = corrValue\n",
    "    for spearmanIndex, corrValue in zip(spearmanAucIncides,spearmanAucValues):\n",
    "        columnName = int(round(spearmanIndex * matrixDf.distance.max()))\n",
    "        resultsDf.loc[\"spearman\", columnName] = corrValue\n",
    "    return resultsDf\n",
    "\n",
    "  \n",
    "def plotPearsonCorrelationDf(pResultsDfList, pLegendList, pOutfile, pMethod=\"pearson\"):\n",
    "    #helper function to plot distance-stratified Pearson correlation stored in pandas dataframes\n",
    "    if pMethod not in [\"pearson\", \"spearman\"]:\n",
    "        print(\"plotting only supported for 'pearson' and 'spearman' correlation methods\")\n",
    "        return\n",
    "    if pResultsDfList is None or pLegendList is None:\n",
    "        return\n",
    "    if not isinstance(pResultsDfList,list) or not isinstance(pLegendList,list):\n",
    "        return\n",
    "    legendStrList = [str(x) for x in pLegendList]\n",
    "    if len(pResultsDfList) != len(legendStrList):\n",
    "        msg = \"can't plot, too many / too few legends\\n\"\n",
    "        msg += \"no. of legend entries should be: {:d}, given {:d}\"\n",
    "        msg = msg.format(len(pResultsDfList), len(legendStrList))\n",
    "        print(msg)\n",
    "        return\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_ylabel(\"{:s} correlation\".format(pMethod[0].upper() + pMethod[1:] ))\n",
    "    ax1.set_xlabel(\"Genomic distance / Mbp\")\n",
    "    trainChromSet = set()\n",
    "    targetChromSet = set()\n",
    "    trainCellLineSet = set()\n",
    "    targetCellLineSet = set()\n",
    "    maxXVal = 0\n",
    "    for i, resultsDf in enumerate(pResultsDfList):\n",
    "        try:\n",
    "            resolutionInt = int(resultsDf.loc[pMethod, 'binsize'])\n",
    "            windowsize_bp = int(resultsDf.loc[pMethod, 'windowsize'])\n",
    "            trainChromSet.add(resultsDf.loc[pMethod, 'modelChroms'])\n",
    "            targetChromSet.add(resultsDf.loc[pMethod, 'targetChrom'])\n",
    "            trainCellLineSet.add(resultsDf.loc[pMethod, 'modelCellLines'])\n",
    "            targetCellLineSet.add(resultsDf.loc[pMethod, 'targetCellLine'])\n",
    "            area_under_corr_curve = resultsDf.loc[pMethod, 'AUC']\n",
    "            maxDist_bp = int(windowsize_bp / resolutionInt)\n",
    "            columnNameList = [x for x in range(maxDist_bp)]\n",
    "            corrXValues = np.arange(maxDist_bp) * resolutionInt / 1000000\n",
    "            corrYValues = resultsDf.loc[pMethod, columnNameList].values.astype(\"float32\")\n",
    "        except Exception as e:\n",
    "            msg = str(e) + \"\\n\"\n",
    "            msg += \"results dataframe {:d} does not contain all relevant fields (binsize, distance stratified pearson correlation data etc.)\"\n",
    "            msg = msg.format(i)\n",
    "            print(msg)\n",
    "        label = pLegendList[i]\n",
    "        if label is None:\n",
    "            label = pMethod + \" / AUC: {:.3f}\".format(area_under_corr_curve)\n",
    "        else:\n",
    "            label = label + \" / AUC: {:.3f}\".format(area_under_corr_curve)\n",
    "        ax1.plot(corrXValues, corrYValues, label = label)\n",
    "        maxXVal = max(maxXVal, corrXValues[-1])\n",
    "    titleStr = \"Pearson correlation vs. genomic distance\"\n",
    "    if len(trainChromSet) == len(targetChromSet) == len(trainCellLineSet) == len(targetCellLineSet) == 1:\n",
    "        titleStr += \"\\n {:s}, {:s} on {:s}, {:s}\"\n",
    "        titleStr = titleStr.format(list(trainCellLineSet)[0], list(trainChromSet)[0], list(targetCellLineSet)[0], list(targetChromSet)[0])\n",
    "    ax1.set_title(titleStr)\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_xlim([0,maxXVal])\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(frameon=False, loc=\"upper right\")\n",
    "    \n",
    "    if pOutfile is None:\n",
    "        outfile = \"correlation.png\"\n",
    "        fig1.savefig(outfile)\n",
    "    else:\n",
    "        outfile = pOutfile\n",
    "        if os.path.splitext(outfile)[1] not in ['.png', '.svg', '.pdf']:\n",
    "            outfile = os.path.splitext(pOutfile)[0] + '.png'\n",
    "            msg = \"Outfile must have png, pdf or svg file extension.\\n\"\n",
    "            msg += \"Renamed outfile to {:s}\".format(outfile)\n",
    "            print(msg)\n",
    "        fig1.savefig(outfile)\n",
    "    plt.close(fig1)\n",
    "    del fig1, ax1\n",
    "\n",
    "def getCorrelation(pData, pDistanceField, pTargetField, pPredictionField, pCorrMethod):\n",
    "    \"\"\"\n",
    "    Helper method to calculate correlation\n",
    "    This method has originally been written by Andre Bajorat during his study project,\n",
    "    licensed under the MIT License: \n",
    "    https://github.com/abajorat/HiCPrediction/blob/master/hicprediction/predict.py\n",
    "    It has been adapted by Ralf Krauth during his study project:\n",
    "    https://github.com/MasterprojectRK/HiCPrediction/blob/master/hicprediction/predict.py\n",
    "    \n",
    "    Parameters:\n",
    "        pData (pandas.DataFrame): Pandas dataframe with read counts / distances\n",
    "        pDistanceField (str): the column name of the distance Field in the dataframe\n",
    "        pTargetField (str): the column name of the target read counts in the dataframe\n",
    "        pPredictionField (str): column name of the predicted read counts in the dataframe\n",
    "        pCorrMethod (str): any of the correlation methods supported by pandas DataFrame corr method\n",
    "    \n",
    "    Returns:\n",
    "        indices (list): integer list of index values \n",
    "        values (list): float list of correlation values\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate the Correlation Matrix\n",
    "    correlation_matrix = pData.groupby(pDistanceField, group_keys=False)[[pTargetField, pPredictionField]].corr(method=pCorrMethod)\n",
    "\n",
    "    # Step 2: Extracting Relevant Correlation Values\n",
    "    correlation_values = correlation_matrix.iloc[0::2, -1].reset_index(drop=True)\n",
    "\n",
    "    # Step 3: Handling NaNs\n",
    "    correlation_values.dropna(inplace=True)\n",
    "\n",
    "    # Step 4: Preparing the Output\n",
    "    indices = correlation_values.index.tolist()\n",
    "    indices = np.array(indices, dtype=np.int32)\n",
    "    max_distance = pData[pDistanceField].max()\n",
    "    indices = indices / max_distance\n",
    "\n",
    "    values = correlation_values.values\n",
    "\n",
    "    # Return the final indices and values\n",
    "    return indices, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cafae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreAndPlot(correlationMethodList, errorType, outputFolder, dataFolder, tadFolder, matrixOutputName, originalDataMatrix, correlationDepth, testChromosomes, trainingChromosomes, trainingCellType, testCellType, binSize, threads, genomicRegion):\n",
    "\n",
    "    try:\n",
    "        cooler_file1 = cooler.Cooler(os.path.join(dataFolder, matrixOutputName))\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(os.path.join(dataFolder, matrixOutputName))\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        cooler_file2 = cooler.Cooler(originalDataMatrix)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(originalDataMatrix)\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    os.makedirs(os.path.join(outputFolder, \"scores_txt\"), exist_ok=True)\n",
    "\n",
    "    matrixOutputNameWithoutExt = os.path.splitext(matrixOutputName)[0]\n",
    "    score_dict = {}\n",
    "    for correlationMethod in correlationMethodList:\n",
    "        \n",
    "        for chromosome in testChromosomes:\n",
    "            if chromosome not in cooler_file1.chromnames:\n",
    "                return\n",
    "            if chromosome not in cooler_file2.chromnames:\n",
    "                return\n",
    "        \n",
    "        if correlationMethod == 'pearson_spearman':\n",
    "            for chrom in testChromosomes:\n",
    "                score_dataframe = computePearsonCorrelation(pCoolerFile1=os.path.join(dataFolder, matrixOutputName), pCoolerFile2=originalDataMatrix,\n",
    "                                                            pWindowsize_bp=correlationDepth, pModelChromList=trainingChromosomes, pTargetChromStr=chrom,\n",
    "                                                            pModelCellLineList=trainingCellType, pTargetCellLineStr=testCellType,\n",
    "                                                            pPlotOutputFile=None, pCsvOutputFile=None)\n",
    "                for correlationMethod_ in ['pearson', 'spearman']:\n",
    "                    for errorType_ in errorType:\n",
    "                        if correlationMethod_ + '_' + errorType_ in score_dict:\n",
    "                            score_dict[correlationMethod_ + '_' + errorType_] += score_dataframe.loc[correlationMethod_, errorType_]\n",
    "                        else:\n",
    "                            score_dict[correlationMethod_ + '_' + errorType_] = score_dataframe.loc[correlationMethod_, errorType_]\n",
    "\n",
    "            for correlationMethod_ in ['pearson', 'spearman']:\n",
    "                for errorType_ in errorType:\n",
    "                    score_dict[correlationMethod_ + '_' + errorType_] = score_dict[correlationMethod_ + '_' + errorType_] / len(testChromosomes)\n",
    "            # score = score / len(testChromosomes)\n",
    "\n",
    "        elif correlationMethod == 'hicrep':\n",
    "            cool1, binSize1 = readMcool(os.path.join(\n",
    "                dataFolder, matrixOutputName), -1)\n",
    "            cool2, binSize2 = readMcool(originalDataMatrix, -1)\n",
    "\n",
    "            # smoothing window half-size\n",
    "            h = 5\n",
    "\n",
    "            # maximal genomic distance to include in the calculation\n",
    "            dBPMax = 1000000\n",
    "\n",
    "            # whether to perform down-sampling or not\n",
    "            # if set True, it will bootstrap the data set # with larger contact counts to\n",
    "            # the same number of contacts as in the other data set; otherwise, the contact\n",
    "            # matrices will be normalized by the respective total number of contacts\n",
    "            bDownSample = False\n",
    "\n",
    "            # Optionally you can get SCC score from a subset of chromosomes\n",
    "            sccSub = hicrepSCC(cool1, cool2, h, dBPMax,\n",
    "                                bDownSample, testChromosomes)\n",
    "\n",
    "            score_dict[correlationMethod] = np.mean(sccSub)\n",
    "        elif correlationMethod == 'TAD_score_MSE' or correlationMethod == 'TAD_fraction':\n",
    "            \n",
    "            os.makedirs(os.path.join(outputFolder, \"tads_predicted_\" + matrixOutputNameWithoutExt), exist_ok=True)\n",
    "            \n",
    "            chromosomes = ' '.join(testChromosomes)\n",
    "            arguments_tad = \"--matrix {} --minDepth {} --maxDepth {} --step {} --numberOfProcessors {}  \\\n",
    "                            --outPrefix {} --minBoundaryDistance {} \\\n",
    "                            --correctForMultipleTesting fdr --thresholdComparisons 0.5 --chromosomes {}\".format(os.path.join(dataFolder,  matrixOutputName), binSize * 3, binSize * 10, binSize, threads,\n",
    "                            os.path.join(outputFolder, \"tads_predicted_\" + matrixOutputNameWithoutExt) + '/tads', 100000, chromosomes).split()\n",
    "            try:\n",
    "                hicFindTADs.main(arguments_tad)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                print(os.path.join(dataFolder, matrixOutputName))\n",
    "                print(e)\n",
    "                return\n",
    "\n",
    "            if correlationMethod == 'TAD_score_MSE':\n",
    "                tad_score_predicted = os.path.join(\n",
    "                    outputFolder, \"tads_predicted_\" + matrixOutputNameWithoutExt) + '/tads_score.bedgraph'\n",
    "                tad_score_orgininal = os.path.join(\n",
    "                    tadFolder, \"tads_original\") + '/tads_score.bedgraph'\n",
    "\n",
    "                tad_score_predicted_df = pd.read_csv(tad_score_predicted, names=[\n",
    "                                                        'chromosome', 'start', 'end', 'score'], sep='\\t')\n",
    "                tad_score_orgininal_df = pd.read_csv(tad_score_orgininal, names=[\n",
    "                                                        'chromosome', 'start', 'end', 'score'], sep='\\t')\n",
    "\n",
    "            \n",
    "                mean_sum_of_squares = ((tad_score_predicted_df['score'] - tad_score_orgininal_df['score']) ** 2).mean()\n",
    "                score_dict[correlationMethod] = mean_sum_of_squares\n",
    "            elif correlationMethod == 'TAD_fraction':\n",
    "                tad_boundaries_predicted = os.path.join(\n",
    "                    outputFolder, \"tads_predicted_\" + matrixOutputNameWithoutExt) + '/tads_boundaries.bed'\n",
    "                tad_boundaries_orgininal = os.path.join(\n",
    "                    tadFolder, \"tads_original\") + '/tads_boundaries.bed'\n",
    "\n",
    "                tad_boundaries_predicted_df = pd.read_csv(tad_boundaries_predicted, names=[\n",
    "                                                        'chromosome', 'start', 'end', 'name', 'score', '.'], sep='\\t')\n",
    "                tad_boundaries_orgininal_df = pd.read_csv(tad_boundaries_orgininal, names=[\n",
    "                                                        'chromosome', 'start', 'end', 'name', 'score', '.'], sep='\\t')\n",
    "                \n",
    "                tad_fraction = len(tad_boundaries_predicted_df) / len(tad_boundaries_orgininal_df)\n",
    "                \n",
    "                exact_matches = pd.merge(tad_boundaries_predicted_df[['chromosome', 'start', 'end']],\n",
    "                                        tad_boundaries_orgininal_df[['chromosome', 'start', 'end']],\n",
    "                                        on=['chromosome', 'start', 'end'], how='inner')\n",
    "                tad_fraction_exact_match = len(exact_matches) / len(tad_boundaries_orgininal_df)\n",
    "\n",
    "                score_dict[correlationMethod] = tad_fraction\n",
    "                score_dict[correlationMethod + '_exact_match'] = tad_fraction_exact_match\n",
    "        elif correlationMethod == 'distribution_fraction':\n",
    "            pass\n",
    "\n",
    "    score_dict[\"hicrep\" + '*' + \"TAD_fraction\" + '*' + \"TAD_exact_match_fraction\"] = score_dict[\"hicrep\"] * score_dict['TAD_fraction'] * score_dict[\"TAD_fraction_exact_match\"]\n",
    "    score_dict[\"(\" +\"hicrep\" + '+' + \"TAD_fraction\" + '+' + \"TAD_exact_match_fraction)\" + '/3'] = (score_dict[\"hicrep\"] + score_dict['TAD_fraction'] + score_dict[\"TAD_fraction_exact_match\"]) / 3\n",
    "\n",
    "    score_dict[\"TAD_score_MSE\" + '*' + \"1-TAD_fraction\" + '*' + \"1-TAD_exact_match_fraction\"] = score_dict[\"TAD_score_MSE\"] * score_dict['TAD_fraction'] * score_dict[\"TAD_fraction_exact_match\"]\n",
    "    score_dict[\"(TAD_score_MSE\" + '+' + \"1-TAD_fraction\" + '+' + \"1-TAD_exact_match_fraction)\" + '/3'] = (score_dict[\"TAD_score_MSE\"] + (1- score_dict['TAD_fraction']) + (1-score_dict[\"TAD_fraction_exact_match\"])) / 3\n",
    "\n",
    "    if genomicRegion:\n",
    "        score_text = \"\\n\".join([f\"{key}: {value:.4f}\" for key, value in score_dict.items()])\n",
    "        print(score_text)\n",
    "        score_file_path = os.path.join(outputFolder, \"scores_txt\", matrixOutputNameWithoutExt + \"_score_summary.txt\")\n",
    "\n",
    "        with open(score_file_path, 'w') as score_file:\n",
    "            score_file.write(score_text)\n",
    "        \n",
    "        score_text = score_text.replace(\"\\n\", \"; \")\n",
    "        browser_tracks_with_hic = \"\"\"\n",
    "[hic matrix]\n",
    "file = {0}\n",
    "title = {2}\n",
    "depth = {4}\n",
    "transform = log1p\n",
    "file_type = hic_matrix\n",
    "show_masked_bins = false\n",
    "\n",
    "[spacer]\n",
    "height = 0.5\n",
    "\n",
    "[TAD seperation score]\n",
    "file = {5}\n",
    "height = 2\n",
    "type = lines\n",
    "individual_color = grey\n",
    "pos_score_in_bin = center\n",
    "summary_color = #1f77b4\n",
    "show_data_range = true\n",
    "file_type = bedgraph_matrix\n",
    "\n",
    "[spacer]\n",
    "height = 1\n",
    "\n",
    "[hic matrix]\n",
    "file = {1}\n",
    "title = original matrix {3}\n",
    "depth = {4}\n",
    "transform = log1p\n",
    "file_type = hic_matrix\n",
    "show_masked_bins = false\n",
    "orientation = inverted\n",
    "\n",
    "[spacer]\n",
    "height = 0.5\n",
    "\n",
    "[TAD seperation score]\n",
    "file = {6}\n",
    "height = 2\n",
    "type = lines\n",
    "individual_color = grey\n",
    "pos_score_in_bin = center\n",
    "summary_color = #1f77b4\n",
    "show_data_range = true\n",
    "file_type = bedgraph_matrix\n",
    "    \"\"\".format(os.path.join(dataFolder, matrixOutputName), originalDataMatrix, score_text, trainingCellType, 2000000, \\\n",
    "               os.path.join(outputFolder, \"tads_predicted_\" + matrixOutputNameWithoutExt, 'tads_tad_score.bm'), \\\n",
    "                os.path.join(tadFolder, \"tads_original\", 'tads_tad_score.bm'))\n",
    "\n",
    "        tracks_path = os.path.join(\n",
    "            outputFolder, \"browser_tracks_hic.ini\")\n",
    "        with open(tracks_path, 'w') as fh:\n",
    "            fh.write(browser_tracks_with_hic)\n",
    "\n",
    "        outfile = os.path.join(\n",
    "            outputFolder, \"pygenometracks\", matrixOutputNameWithoutExt + \".pdf\")\n",
    "\n",
    "        arguments = f\"--tracks {tracks_path} --region {genomicRegion} \"\\\n",
    "                    f\"--outFileName {outfile} --trackLabelFraction 0.1 --width 38 --height 35\".split()\n",
    "        try:\n",
    "            pygenometracks.plotTracks.main(arguments)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(os.path.join(dataFolder, matrixOutputName))\n",
    "            print(originalDataMatrix)\n",
    "            print(e)\n",
    "\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af406f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTADTrack(originalDataMatrix, binSize, threads, chromosomes, outputFolder):\n",
    "    os.makedirs(os.path.join(outputFolder, \"tads_original\"), exist_ok=True)\n",
    "\n",
    "    chromosomes_string = 'chr '.join(chromosomes)\n",
    "    print(chromosomes_string)\n",
    "    arguments_tad = \"--matrix {} --minDepth {} --maxDepth {} --step {} --numberOfProcessors {}  \\\n",
    "                        --outPrefix {} --minBoundaryDistance {} \\\n",
    "                        --correctForMultipleTesting fdr --thresholdComparisons 0.5 --chromosomes {}\".format(originalDataMatrix, binSize * 3, binSize * 10, binSize, threads,\n",
    "                    os.path.join(outputFolder, \"tads_original\") + '/tads', 100000, chromosomes_string).split()\n",
    "    print(arguments_tad)\n",
    "    hicFindTADs.main(arguments_tad)\n",
    "    tad_score_orgininal = os.path.join(\n",
    "        outputFolder, \"tads_original\") + '/tads_score.bedgraph'\n",
    "    tad_score_orgininal_df = pd.read_csv(tad_score_orgininal, names=[\n",
    "                                            'chromosome', 'start', 'end', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b190c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMethod = ['pearson_spearman', 'hicrep', 'TAD_fraction', 'TAD_score_MSE', 'distribution_fraction']\n",
    "errorType = ['R2', 'MSE', 'MAE', 'MSLE', 'AUC']\n",
    "outputFolder = os.path.join(ROOT_PATH_25KB, \"result\")\n",
    "dataFolder = ROOT_PATH_25KB_predicted\n",
    "tadFolder = outputFolder\n",
    "originalDataMatrix = hic_matrix_25kb_path\n",
    "correlationDepth = 1000000\n",
    "testChromosomes = ['1']\n",
    "trainingChromosomes = ['1']\n",
    "trainingCellType = \"GM12878\"\n",
    "testCellType = \"GM12878\"\n",
    "binSize = 25000\n",
    "threads = 5\n",
    "genomicRegion = \"1:18000000-22000000\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff16ffe",
   "metadata": {},
   "source": [
    "### create the TAD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "createTADTrack(hic_matrix_25kb_path, binSize, threads, testChromosomes, outputFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a04502",
   "metadata": {},
   "source": [
    "### Score the predict matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hicrep_multi = 0\n",
    "max_hicrep_mean = 0\n",
    "max_hicrep = 0\n",
    "\n",
    "min_tad_score_mse_multi = 1\n",
    "min_tad_score_mse_mean = 1\n",
    "min_tad_score_mse = 1\n",
    "\n",
    "max_hicrep_multi_id = \"\"\n",
    "max_hicrep_mean_id = \"\"\n",
    "max_hicrep_id = \"\"\n",
    "\n",
    "\n",
    "min_tad_score_mse_multi_id = \"\"\n",
    "min_tad_score_mse_mean_id = \"\"\n",
    "min_tad_score_mse_id = \"\"\n",
    "\n",
    "\n",
    "scores = {}\n",
    "scores_none = []\n",
    "for file in files_25kb:\n",
    "\n",
    "    score_dict = scoreAndPlot(correlationMethod, errorType, outputFolder, dataFolder, tadFolder, file, originalDataMatrix, correlationDepth, testChromosomes, trainingChromosomes, trainingCellType, testCellType, binSize, threads, genomicRegion)\n",
    "    if score_dict is None:\n",
    "        scores_none.append(file)\n",
    "        continue\n",
    "    scores[file] = score_dict\n",
    "    if max_hicrep_multi < score_dict[\"hicrep\" + '*' + \"TAD_fraction\" + '*' + \"TAD_exact_match_fraction\"]:\n",
    "        max_hicrep_multi = score_dict[\"hicrep\" + '*' + \"TAD_fraction\" + '*' + \"TAD_exact_match_fraction\"]\n",
    "        max_hicrep_multi_id = file\n",
    "    \n",
    "    if max_hicrep_mean < score_dict[\"(\" +\"hicrep\" + '+' + \"TAD_fraction\" + '+' + \"TAD_exact_match_fraction)\" + '/3'] :\n",
    "        max_hicrep_mean = score_dict[\"(\" +\"hicrep\" + '+' + \"TAD_fraction\" + '+' + \"TAD_exact_match_fraction)\" + '/3'] \n",
    "        max_hicrep_mean_id = file\n",
    "\n",
    "    if max_hicrep < score_dict[\"hicrep\"]:\n",
    "        max_hicrep = score_dict[\"hicrep\"]\n",
    "        max_hicrep_id = file\n",
    "\n",
    "    \n",
    "    if min_tad_score_mse_multi > score_dict[\"TAD_score_MSE\" + '*' + \"1-TAD_fraction\" + '*' + \"1-TAD_exact_match_fraction\"]:\n",
    "        min_tad_score_mse_multi = score_dict[\"TAD_score_MSE\" + '*' + \"1-TAD_fraction\" + '*' + \"1-TAD_exact_match_fraction\"]\n",
    "        min_tad_score_mse_multi_id = file\n",
    "    \n",
    "    if min_tad_score_mse_mean > score_dict[\"(TAD_score_MSE\" + '+' + \"1-TAD_fraction\" + '+' + \"1-TAD_exact_match_fraction)\" + '/3']:\n",
    "        min_tad_score_mse_mean = score_dict[\"(TAD_score_MSE\" + '+' + \"1-TAD_fraction\" + '+' + \"1-TAD_exact_match_fraction)\" + '/3']\n",
    "        min_tad_score_mse_mean_id = file\n",
    "    \n",
    "    if min_tad_score_mse > score_dict[\"TAD_score_MSE\"]:\n",
    "        min_tad_score_mse = score_dict[\"TAD_score_MSE\"]\n",
    "        min_tad_score_mse_id = file\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Max hicrep multiplication {} with: {}\".format(max_hicrep_multi_id, max_hicrep_multi))\n",
    "print(\"Max hicrep mean {} with: {}\".format(max_hicrep_mean_id, max_hicrep_mean))\n",
    "print(\"Max hicrep {} with: {}\".format(max_hicrep_id, max_hicrep))\n",
    "\n",
    "print(\"Min TAD score MSE multiplication {} with: {}\".format(min_tad_score_mse_multi_id, min_tad_score_mse_multi))\n",
    "print(\"Min TAD score MSE mean {} with: {}\".format(min_tad_score_mse_mean_id, min_tad_score_mse_mean))\n",
    "print(\"Min TAD score MSE {} with: {}\".format(min_tad_score_mse_id, min_tad_score_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {key.replace('.cool', ''): value for key, value in scores.items()}\n",
    "scores_df = pd.DataFrame.from_dict(scores, orient='index')\n",
    "scores_df.reset_index(inplace=True)\n",
    "scores_df.rename(columns={'index': 'File'}, inplace=True)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc287d88",
   "metadata": {},
   "source": [
    "### Load the human ranking file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_file_path = os.path.join(ROOT_PATH,'image_rankings.csv')\n",
    "ranking_df = pd.read_csv(ranking_file_path)\n",
    "print(ranking_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df['Image'] = ranking_df['Image'].str.replace('static/images/', '').str.replace('.jpg', '')\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b959f3b",
   "metadata": {},
   "source": [
    "### Merge the scored dataframe with the human ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = scores_df.merge(ranking_df, left_on='File', right_on='Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(ROOT_PATH, 'merged_df.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ega_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
