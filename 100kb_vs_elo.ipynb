{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# set the base directory you want to search\n",
    "base_path = '/Volumes/ag-heidel/wolffjoa/hyperparamter_score/scored_100kb'  # change this to your target path\n",
    "\n",
    "# find all files with \"final_scores\" in the name recursively\n",
    "pattern = os.path.join(base_path, '**', 'final_scores*')\n",
    "files = glob.glob(pattern, recursive=True)\n",
    "\n",
    "# dictionary to hold the results\n",
    "results = {}\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    # split the file name by '_' and get the 5th entry if available (index 4)\n",
    "    parts = filename.split('_')\n",
    "    file_name_key = parts[9] if len(parts) >= 10 else filename\n",
    "    # print(file_name_key)\n",
    "    # load the text file where the first column is the key and the second column is the value\n",
    "    mapping = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            # assuming whitespace separated values\n",
    "            columns = line.strip().split()\n",
    "            if line.lstrip().startswith('Matrix'):\n",
    "                continue\n",
    "            if len(columns) >= 2:\n",
    "                key, value = columns[0], columns[1]\n",
    "                mapping[key] = value\n",
    "\n",
    "    results[file_name_key] = mapping\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame([{'Name': name, **inner_dict} for name, inner_dict in results.items()])\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.dropna()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the actual path to your ELO file\n",
    "elo_file_path = '/Users/wolffjoa/src/image-ranker/image_rankings_100kb.csv'\n",
    "df_elo = pd.read_csv(elo_file_path)\n",
    "df_elo['Image'] = df_elo['Image'].apply(lambda x: os.path.basename(x).split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_results, df_elo, left_on='Name', right_on='Image')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns except 'Name' to float in merged_df\n",
    "cols_to_float = merged_df.columns.drop('Name').drop('Image')\n",
    "merged_df[cols_to_float] = merged_df[cols_to_float].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the y-variables: include 'pearson AUC', 'hicrep' and any columns that start with 'best_model'\n",
    "y_columns = []\n",
    "if 'pearson_AUC:' in merged_df.columns:\n",
    "    y_columns.append('pearson_AUC:')\n",
    "if 'hicrep:' in merged_df.columns:\n",
    "    y_columns.append('hicrep:')\n",
    "if 'TAD_score_MSE:' in merged_df.columns:\n",
    "    y_columns.append('TAD_score_MSE:')\n",
    "if 'TAD_fraction:' in merged_df.columns:\n",
    "    y_columns.append('TAD_fraction:')\n",
    "if 'TAD_fraction_exact_match:' in merged_df.columns:\n",
    "    y_columns.append('TAD_fraction_exact_match:')\n",
    "y_columns.extend([col for col in merged_df.columns if col.startswith('best_model')])\n",
    "\n",
    "wrong_scoring = {}\n",
    "MSE_all = {}\n",
    "# Calculate the grid dimensions for subplots (5 per row)\n",
    "n_plots = len(y_columns)\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4), sharex=True)\n",
    "# Flatten axes for easier iteration (handles both 1D and 2D arrays)\n",
    "if n_rows == 1:\n",
    "    ax_list = axes\n",
    "else:\n",
    "    ax_list = axes.flatten()\n",
    "\n",
    "for idx, y in enumerate(y_columns):\n",
    "    ax = ax_list[idx]\n",
    "    print(y)\n",
    "    # Convert the column to numeric values if possible\n",
    "    # y_data = pd.to_numeric(merged_df[y], errors='coerce')\n",
    "    # Normalize the 'pearson_AUC:' column for the x-axis\n",
    "    # Define the x data column using a variable\n",
    "    x_column = 'ELO'\n",
    "    \n",
    "    merged_df[x_column] = pd.to_numeric(merged_df[x_column], errors='coerce')\n",
    "    x_min = merged_df[x_column].min()\n",
    "    x_max = merged_df[x_column].max()\n",
    "    merged_df[x_column] = (merged_df[x_column] - x_min) / (x_max - x_min)\n",
    "    \n",
    "    # Normalize the current y column for the y-axis\n",
    "    merged_df[y] = pd.to_numeric(merged_df[y], errors='coerce')\n",
    "    y_min = merged_df[y].min()\n",
    "    y_max = merged_df[y].max()\n",
    "    merged_df[y] = (merged_df[y] - y_min) / (y_max - y_min)\n",
    "    \n",
    "    ax.scatter(merged_df[x_column], merged_df[y])\n",
    "    mse = np.mean((merged_df[x_column] - merged_df[y]) ** 2)\n",
    "    MSE_all[y] = mse\n",
    "    ax.text(0.95, 0.05, f'MSE: {mse:.4f}', transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "    ax.set_xlabel(x_column.replace(\":\", \"\"))\n",
    "    title_text = y.split(\".degree\")[0].replace('-', ' ').replace('fraction_exact_match', 'FEM').replace('_', ' ').replace(\"best model\", \"\").replace('.pkl', '').replace(\"pearson\", 'Pearson').replace(\"hicrep\", 'HiCRep').strip(\".\").strip(\":\")\n",
    "    ax.set_title(f'{title_text}')\n",
    "\n",
    "\n",
    "# Create a mask for points you want to annotate\n",
    "    mask = ((merged_df[x_column] >= 0.7) & (merged_df[y] <= 0.2)) | ((merged_df[x_column] <= 0.2) & (merged_df[y] >= 0.7))\n",
    "    # Collect matching IDs for the current y column in a dictionary\n",
    "    match_ids = {}\n",
    "    cond1 = (merged_df[x_column] >= 0.7) & (merged_df[y] <= 0.2)\n",
    "    cond2 = (merged_df[x_column] <= 0.2) & (merged_df[y] >= 0.7)\n",
    "    match_ids['high_x_low_y'] = merged_df.loc[cond1, 'Name'].tolist()\n",
    "    match_ids['low_x_high_y'] = merged_df.loc[cond2, 'Name'].tolist()\n",
    "    wrong_scoring[y] = match_ids\n",
    "    print(f\"{title_text} matching IDs:\", match_ids)\n",
    "    # Prepare annotations\n",
    "    import matplotlib.patheffects as path_effects\n",
    "    texts = []\n",
    "    for idx in merged_df[mask].index:\n",
    "        txt = ax.text(\n",
    "            merged_df.loc[idx, x_column], \n",
    "            merged_df.loc[idx, y], \n",
    "            merged_df.loc[idx, 'Name'], \n",
    "            fontsize=8, \n",
    "            ha='center', \n",
    "            va='center',\n",
    "            color='black',\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7)\n",
    "        )\n",
    "        txt.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=1, foreground='white'),\n",
    "            path_effects.Normal()\n",
    "        ])\n",
    "        texts.append(txt)\n",
    "\n",
    "    # Adjust labels to avoid overlaps\n",
    "    adjust_text(\n",
    "        texts, \n",
    "        ax=ax, \n",
    "        arrowprops=dict(arrowstyle='-', color='grey', lw=0.5),\n",
    "        expand_points=(1.2, 1.2),  # Controls how far labels can move\n",
    "        expand_text=(1.2, 1.2),\n",
    "        force_points=0.2,          # Adjust force parameters as needed\n",
    "        force_text=0.2,\n",
    "        lim=100                     # Limit iterations to improve performance\n",
    "    )\n",
    "    # Add a red dashed line representing x = y\n",
    "    ax.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1)\n",
    "    \n",
    "        # plt.show()\n",
    "    # Add a bottom-right corner annotation clearly\n",
    "    # ax.annotate(\n",
    "    #     f\"{title_text}: {value}\",\n",
    "    #     xy=(0.95, 0.05),\n",
    "    #     xycoords='axes fraction',\n",
    "    #     xytext=(-10, 10),\n",
    "    #     textcoords='offset points',\n",
    "    #     fontsize=10,\n",
    "    #     verticalalignment='bottom',\n",
    "    #     horizontalalignment='right',\n",
    "    #     bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    # )   \n",
    "        # Turn off any unused subplots\n",
    "for ax in ax_list[n_plots:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"/Users/wolffjoa/data_local\", 'prediction_vs_human_100kb_per_score.pdf'), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = {}\n",
    "\n",
    "for scoring, score_dict in wrong_scoring.items():\n",
    "    print(scoring)\n",
    "    for condition, ids in score_dict.items():\n",
    "        print(f\"  {condition}: {len(ids)}\")\n",
    "\n",
    "for score_dict in wrong_scoring.values():\n",
    "    # for ids in score_dict.values():\n",
    "    count = sum(len(ids) for ids in score_dict.values())\n",
    "    binning[count] = binning.get(count, 0) + 1\n",
    "\n",
    "print(\"Binning of number of elements:\")\n",
    "for num_elements in sorted(binning):\n",
    "    print(f\"{num_elements} elements: {binning[num_elements]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_MSE = {\n",
    "    key.split(\".degree\")[0]\n",
    "          .replace('-', ' ')\n",
    "          .replace('fraction_exact_match', 'FEM')\n",
    "          .replace('_', ' ')\n",
    "          .replace(\"best model\", \"\")\n",
    "          .replace('.pkl', '')\n",
    "          .replace(\"pearson\", 'Pearson')\n",
    "          .replace(\"hicrep\", 'HiCRep')\n",
    "          .strip(\".\")\n",
    "          .strip(\":\"): mse\n",
    "    for key, mse in MSE_all.items()\n",
    "}\n",
    "\n",
    "print(renamed_MSE)\n",
    "sorted_MSE = dict(sorted(renamed_MSE.items(), key=lambda item: item[1]))\n",
    "print(sorted_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "from matplotlib.text import Annotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the y-variables: include 'pearson AUC', 'hicrep' and any columns that start with 'best_model'\n",
    "y_columns = []\n",
    "if 'pearson_AUC:' in merged_df.columns:\n",
    "    y_columns.append('pearson_AUC:')\n",
    "if 'hicrep:' in merged_df.columns:\n",
    "    y_columns.append('hicrep:')\n",
    "if 'TAD_score_MSE:' in merged_df.columns:\n",
    "    y_columns.append('TAD_score_MSE:')\n",
    "if 'TAD_fraction:' in merged_df.columns:\n",
    "    y_columns.append('TAD_fraction:')\n",
    "if 'TAD_fraction_exact_match:' in merged_df.columns:\n",
    "    y_columns.append('TAD_fraction_exact_match:')\n",
    "y_columns.extend([col for col in merged_df.columns if col.startswith('best_model')])\n",
    "\n",
    "texts_all = {}\n",
    "\n",
    "MSE_all = {}\n",
    "# Calculate the grid dimensions for subplots (5 per row)\n",
    "n_plots = len(y_columns)\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4), sharex=True)\n",
    "# Flatten axes for easier iteration (handles both 1D and 2D arrays)\n",
    "if n_rows == 1:\n",
    "    ax_list = axes\n",
    "else:\n",
    "    ax_list = axes.flatten()\n",
    "\n",
    "for idx, y in enumerate(y_columns):\n",
    "    ax = ax_list[idx]\n",
    "    print(y)\n",
    "    # Convert the column to numeric values if possible\n",
    "    # y_data = pd.to_numeric(merged_df[y], errors='coerce')\n",
    "    # Normalize the 'pearson_AUC:' column for the x-axis\n",
    "    # Define the x data column using a variable\n",
    "    x_column = 'ELO'\n",
    "    \n",
    "    merged_df[x_column] = pd.to_numeric(merged_df[x_column], errors='coerce')\n",
    "    x_min = merged_df[x_column].min()\n",
    "    x_max = merged_df[x_column].max()\n",
    "    merged_df[x_column] = (merged_df[x_column] - x_min) / (x_max - x_min)\n",
    "    \n",
    "    # Normalize the current y column for the y-axis\n",
    "    merged_df[y] = pd.to_numeric(merged_df[y], errors='coerce')\n",
    "    y_min = merged_df[y].min()\n",
    "    y_max = merged_df[y].max()\n",
    "    merged_df[y] = (merged_df[y] - y_min) / (y_max - y_min)\n",
    "    \n",
    "    ax.scatter(merged_df[x_column], merged_df[y])\n",
    "    mse = np.mean((merged_df[x_column] - merged_df[y]) ** 2)\n",
    "    MSE_all[y] = mse\n",
    "    ax.text(0.95, 0.05, f'MSE: {mse:.4f}', transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "    ax.set_xlabel(x_column.replace(\":\", \"\"))\n",
    "    title_text = y.split(\".degree\")[0].replace('-', ' ').replace('fraction_exact_match', 'FEM').replace('_', ' ').replace(\"best model\", \"\").replace('.pkl', '').replace(\"pearson\", 'Pearson').replace(\"hicrep\", 'HiCRep').strip(\".\").strip(\":\")\n",
    "    ax.set_title(f'{title_text}')\n",
    "\n",
    "\n",
    "    # Create a mask for points you want to annotate\n",
    "    \n",
    "    wrong = wrong_scoring.get('hicrep:', {})\n",
    "    high = wrong.get('high_x_low_y', [])\n",
    "    low = wrong.get('low_x_high_y', [])\n",
    "# annotate high points with 'high'\n",
    "    # Annotate high points in red\n",
    "    for name in high:\n",
    "        row = merged_df[merged_df['Name'] == name]\n",
    "        if not row.empty:\n",
    "            x_pos = row[x_column].values[0]\n",
    "            y_pos = row[y].values[0]\n",
    "            txt = ax.annotate(\n",
    "                name,\n",
    "                (x_pos, y_pos),\n",
    "                color='red',\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                bbox=dict(facecolor='white', alpha=0.5, edgecolor='none')\n",
    "            )\n",
    "            txt.set_path_effects([\n",
    "                path_effects.Stroke(linewidth=1, foreground='white'),\n",
    "                path_effects.Normal()\n",
    "            ])\n",
    "\n",
    "    # Annotate low points in blue\n",
    "    for name in low:\n",
    "        row = merged_df[merged_df['Name'] == name]\n",
    "        if not row.empty:\n",
    "            x_pos = row[x_column].values[0]\n",
    "            y_pos = row[y].values[0]\n",
    "            txt = ax.annotate(\n",
    "                name,\n",
    "                (x_pos, y_pos),\n",
    "                color='blue',\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                bbox=dict(facecolor='white', alpha=0.5, edgecolor='none')\n",
    "            )\n",
    "            txt.set_path_effects([\n",
    "                path_effects.Stroke(linewidth=1, foreground='white'),\n",
    "                path_effects.Normal()\n",
    "            ])\n",
    "    ax.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    \n",
    "    #\n",
    "    texts = [child for child in ax.get_children() if isinstance(child, Annotation)]\n",
    "    texts_all[title_text] = texts\n",
    "\n",
    "    # print(texts)\n",
    "    # Adjust the annotations to avoid overlaps and add arrows pointing to their datapoints\n",
    "    # adjust_text(\n",
    "    #     texts,\n",
    "    #     ax=ax,\n",
    "    #     arrowprops=dict(arrowstyle='->', color='grey', lw=0.5),\n",
    "    #     expand_points=(1.2, 1.2),\n",
    "    #     expand_text=(1.2, 1.2)\n",
    "    # )\n",
    "    adjust_text(\n",
    "        texts, \n",
    "        ax=ax,\n",
    "        arrowprops=dict(arrowstyle='->', color='grey'),\n",
    "        expand_points=(2, 2),  # Increase expansion around points to consider points as obstacles\n",
    "        force_points=0.5,      # Adjust force of points to encourage arrow drawing\n",
    "        force_text=0.7,        # Adjust force of texts to push them away slightly\n",
    "        only_move={'points': 'xy', 'texts': 'xy'},  # Allow labels and points movement in xy directions\n",
    "    )\n",
    "    print('y: {}'.format(y))\n",
    "    if y == 'hicrep:' or y == 'best_model.pearson_AUC-TAD_fraction_exact_match-TAD_score_MSE.degree_1.pkl:':\n",
    "        fig_ind, ax_ind = plt.subplots(figsize=(5, 4))\n",
    "        ax_ind.scatter(merged_df[x_column], merged_df[y])\n",
    "        mse_ind = np.mean((merged_df[x_column] - merged_df[y]) ** 2)\n",
    "        ax_ind.text(0.95, 0.05, f'MSE: {mse_ind:.4f}', transform=ax_ind.transAxes, fontsize=12,\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "        ax_ind.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1)\n",
    "        ax_ind.set_xlabel(x_column.replace(\":\", \"\"))\n",
    "        ax_ind.set_ylabel(title_text)\n",
    "        # ax_ind.set_title(title_text)\n",
    "        # texts = []\n",
    "        wrong = wrong_scoring.get('hicrep:', {})\n",
    "        high = wrong.get('high_x_low_y', [])\n",
    "        low = wrong.get('low_x_high_y', [])\n",
    "    # annotate high points with 'high'\n",
    "        # Annotate high points in red\n",
    "        for name in high:\n",
    "            row = merged_df[merged_df['Name'] == name]\n",
    "            if not row.empty:\n",
    "                x_pos = row[x_column].values[0]\n",
    "                y_pos = row[y].values[0]\n",
    "                txt = ax_ind.annotate(\n",
    "                    name,\n",
    "                    (x_pos, y_pos),\n",
    "                    color='red',\n",
    "                    fontsize=10,\n",
    "                    fontweight='bold',\n",
    "                    bbox=dict(facecolor='white', alpha=0.5, edgecolor='none')\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    path_effects.Stroke(linewidth=1, foreground='white'),\n",
    "                    path_effects.Normal()\n",
    "                ])\n",
    "\n",
    "        # Annotate low points in blue\n",
    "        for name in low:\n",
    "            row = merged_df[merged_df['Name'] == name]\n",
    "            if not row.empty:\n",
    "                x_pos = row[x_column].values[0]\n",
    "                y_pos = row[y].values[0]\n",
    "                txt = ax_ind.annotate(\n",
    "                    name,\n",
    "                    (x_pos, y_pos),\n",
    "                    color='blue',\n",
    "                    fontsize=10,\n",
    "                    fontweight='bold',\n",
    "                    bbox=dict(facecolor='white', alpha=0.5, edgecolor='none')\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    path_effects.Stroke(linewidth=1, foreground='white'),\n",
    "                    path_effects.Normal()\n",
    "                ])\n",
    "        ax_ind.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    \n",
    "    #\n",
    "        texts = [child for child in ax_ind.get_children() if isinstance(child, Annotation)]\n",
    "        texts_all[title_text] = texts\n",
    "\n",
    "        # Adjust labels to avoid overlaps\n",
    "        adjust_text(\n",
    "            texts,\n",
    "            ax=ax_ind,\n",
    "            arrowprops=dict(arrowstyle='-', color='grey', lw=0.5),\n",
    "            expand_points=(1.2, 1.2),  # Controls how far labels can move\n",
    "            expand_text=(1.2, 1.2),\n",
    "            force_points=0.2,          # Adjust force parameters as needed\n",
    "            force_text=0.2,\n",
    "            lim=100                    # Limit iterations to improve performance\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        fig_ind.savefig(os.path.join(\"/Users/wolffjoa/data_local\", f\"subplot_{title_text.replace(' ', '_')}.pdf\"), dpi=300)\n",
    "        plt.close(fig_ind)\n",
    "for ax in ax_list[n_plots:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"/Users/wolffjoa/data_local\", 'prediction_vs_human_100kb.pdf'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [text.get_text() for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Define source and destination directories\n",
    "source_folder = '/Users/wolffjoa/src/image-ranker/static/100kb_pdf'\n",
    "dest_folder = os.path.join(source_folder, 'selected_pdfs')\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "# List of IDs to look for at the beginning of the PDF file names\n",
    "pdf_ids = [\n",
    "    '571e8570', '94f3fed9', '31b4ff17', '5be98a17', \n",
    "    'eef49770', 'e79e9b25', '6b74fb7d', '3583c727', \n",
    "    'e52b6646', 'd7172994'\n",
    "]\n",
    "\n",
    "for pdf_id in pdf_ids:\n",
    "    pattern = os.path.join(source_folder, f\"{pdf_id}*.pdf\")\n",
    "    for pdf_file in glob.glob(pattern):\n",
    "        shutil.copy(pdf_file, dest_folder)\n",
    "        print(f\"Copied {pdf_file} to {dest_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Get the list of IDs from the wrong_scoring dictionary for low_x_high_y\n",
    "# (Alternatively, you could also use the pdf_ids list defined earlier)\n",
    "ids_to_plot = wrong.get('low_x_high_y', pdf_ids)\n",
    "\n",
    "for sample_id in ids_to_plot:\n",
    "    pattern = os.path.join(\"/Users/wolffjoa/data_local/hicgan/hyperparameter/100kb\", f\"{sample_id}*.cool\")\n",
    "    matrix_files = glob.glob(pattern)\n",
    "    if matrix_files:\n",
    "        path_matrix = matrix_files[0]\n",
    "    else:\n",
    "        print(f\"Matrix file not found for {sample_id}\")\n",
    "        continue\n",
    "    # Define the genomic region\n",
    "    region = \"chr1:18000000-22000000\"\n",
    "    config_content = \"\"\"[hic matrix]\n",
    "    file = {0}\n",
    "    title = {1}\n",
    "    depth = {2}\n",
    "    transform = log1p\n",
    "    file_type = hic_matrix\n",
    "    show_masked_bins = false\n",
    "    \"\"\".format(path_matrix, sample_id, 2000000,)\n",
    "\n",
    "    with open(\"tracks_config.ini\", \"w\") as f:\n",
    "        f.write(config_content)\n",
    "    # Path to your pyGenomeTracks configuration file (adjust this path as needed)\n",
    "    track_config = \"tracks_config.ini\"  \n",
    "\n",
    "\n",
    "    output_file = f\"100kb_{sample_id}_chr1_18-22Mb.pdf\"\n",
    "    cmd = [\n",
    "       \"pyGenomeTracks\",\n",
    "       \"--tracks\", track_config,\n",
    "       \"--region\", region,\n",
    "       \"--out\", output_file\n",
    "    ]\n",
    "    print(\"Running command:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_dict = {}\n",
    "\n",
    "for group, annotations in texts_all.items():\n",
    "    # For each annotation, get its (x, y) position and compute the average\n",
    "    x_avg = sum(annot.get_position()[0] for annot in annotations) / len(annotations)\n",
    "    y_avg = sum(annot.get_position()[1] for annot in annotations) / len(annotations)\n",
    "    averages = (x_avg, y_avg)\n",
    "    averages_dict[group] = averages\n",
    "\n",
    "print(averages_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ega_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
